model:
  arch: base_arch
  relaxation: True
  fm_reg: null # tuning parameter
  k: 0.5 # tuning parameter
  alpha_0: 0.2 # tuning parameter
  latent_show: False
  visualization: False
  encoder: 
    module1: 
      arch: pointcapsnet
      prim_caps_size : 1024
      prim_vec_size : 16
      latent_caps_size : 32
      latent_vec_size : 16
      num_points : 2048
  decoder: 
    module1: 
      arch: pointcapsnet
      latent_caps_size : 32
      latent_vec_size : 16
      num_points : 2048
trainer: teacher
training:
  n_epoch: 500
  loss:
    type: chamfer
  optimizer:
    name: 'adam'
    lr: 0.0001
    # betas: [0.9, 0.999]
    # weight_decay: 0.000001
  lr_schedule: null
  resume: null
  augmentations: null
  print_interval: 100
logger:
  type: base
data:
  training:
    loader: shapenetcorev2 # tuning parameter
    path: datasets
    split: all
    random_rotate: True
    batch_size: 16
    num_workers: 8
student:
  modelnet10:
    training:
      loader: modelnet10 # tuning parameter
      path: datasets
      split: trainval
      batch_size: 16
      num_workers: 8
    test:
      loader: modelnet10 # tuning parameter
      path: datasets
      split: test
      batch_size: 16
      num_workers: 8
  modelnet40:
    training:
      loader: modelnet40 # tuning parameter
      path: datasets
      split: trainval
      batch_size: 16
      num_workers: 8
    test:
      loader: modelnet40 # tuning parameter
      path: datasets
      split: test
      batch_size: 16
      num_workers: 8