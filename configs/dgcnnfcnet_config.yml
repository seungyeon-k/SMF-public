model:
  arch: base_arch
  relaxation: True
  fm_reg: null # tuning parameter
  k: 0.5 # tuning parameter
  alpha_0: 0.2 # tuning parameter
  latent_show: False
  visualization: False
  encoder: 
    module1: 
      arch: dgcnn_cls
      feat_dims: 512 # tuning parameter
      k: 20
  decoder: 
    module1: 
      arch: mlp_pointcloud
      input_dim: 512 # tuning parameter
      activation: relu
      leakyrelu_slope: None
      out_activation: linear
      l_hidden: [1024, 2048]
      use_batch_norm: False
      output_point_dim: 3
      number_of_points: 2048  
trainer: teacher
training:
  n_epoch: 500
  loss:
    type: chamfer
  optimizer:
    name: 'adam'
    lr: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0.000001
  lr_schedule: null
  resume: null
  augmentations: null
  print_interval: 100
logger:
  type: base
data:
  training:
    loader: shapenetcorev2 # tuning parameter
    path: datasets
    split: all
    random_rotate: True
    batch_size: 16
    num_workers: 8
student:
  modelnet10:
    training:
      loader: modelnet10 # tuning parameter
      path: datasets
      split: trainval
      batch_size: 16
      num_workers: 8
    test:
      loader: modelnet10 # tuning parameter
      path: datasets
      split: test
      batch_size: 16
      num_workers: 8
  modelnet40:
    training:
      loader: modelnet40 # tuning parameter
      path: datasets
      split: trainval
      batch_size: 16
      num_workers: 8
    test:
      loader: modelnet40 # tuning parameter
      path: datasets
      split: test
      batch_size: 16
      num_workers: 8